{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Word2Vec"
      ],
      "metadata": {
        "id": "Z5ppYd9fnEYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often times in machine learning we will come across a set of data that contains words with useful information. However extracting meaning from these texts in a way machine learning models can understand, can be challenging, which is where word embeddings come in."
      ],
      "metadata": {
        "id": "INLrocQ8nJBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding Spaces"
      ],
      "metadata": {
        "id": "TmV3-Xw5irx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a deep neural network, each new layer transforms the input data to create a high dimensionality representation of our previous data. When viewing this layer in a trained neural network, you may begin to notice patterns or groupings. These patterns are created during the training phase and serve to organize similar data which helps the network distinguish between different classes."
      ],
      "metadata": {
        "id": "MA55LIopjmmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png'>"
      ],
      "metadata": {
        "id": "hMjC0HRbivBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word Embeddings"
      ],
      "metadata": {
        "id": "RPxh-GB0nwgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embeddings are simply a vector representation of a word. Below is a basic example with made up parameters."
      ],
      "metadata": {
        "id": "K9oCWsZ-oLC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1200/1*sAJdxEsDjsPMioHyzlN3_A.png\">"
      ],
      "metadata": {
        "id": "F-d9shBTnymA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice in the bottom example where man and women, and king and queen share a simlar spatial pattern. This is one of the main goals of embedding. We want the meaning of these words and relations to other words to be represented in this space. This is also called the semantic relationship between words."
      ],
      "metadata": {
        "id": "pPRZjV6AoIOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How Word2Vec works"
      ],
      "metadata": {
        "id": "ZH5dNcFWotZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a neural network that consists of an input layer a single hidden layer and an output layer using the softmax activation function. The Word2Vec model can be trained in various ways shown below."
      ],
      "metadata": {
        "id": "NvlwYPFRo4TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/45458iDEB69E518EBA3AD9?v=v2\">"
      ],
      "metadata": {
        "id": "C_MWlS3wrOPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Skip-Gram"
      ],
      "metadata": {
        "id": "u_nHdGaYp7In"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a skip-gram model the network is given some text, and for each word in the text, the model has to predict the surrounding context words. By doing this the model trains the hidden or embedding layer and when training is done we use the hidden layer as the output and scrap the output layer."
      ],
      "metadata": {
        "id": "Tzql_gZCqQSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CBOW (Continuous Bag of Words)"
      ],
      "metadata": {
        "id": "Y0I_sG9zrV-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBOW is the opposite of skip-gram, where we try to predict what a certain word will be based on the surrounding context of the word. The output layer is scrapped and the rest of the network is used to create embeddings."
      ],
      "metadata": {
        "id": "K2-7KNz_rRlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Book Recommendation System"
      ],
      "metadata": {
        "id": "gxQ7f3LWrqSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I have a dataset from GoodReads which is one of the largest book review websites. It consists of 52194 books and contains a description as well as author, ISBN, titles, etc."
      ],
      "metadata": {
        "id": "6gsOw9Z8rzcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Book recommendation systems often use the approach of book ratings, authors, etc, to provide you a book recommendation, however, we will be using JUST the description of the book. We will do this by first cleaning our text, then creating word embeddings and using the cosine similarity score to recommend us similar books."
      ],
      "metadata": {
        "id": "PnWmXg3osBMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b9D9ilML-_g1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nHD95e61AERm"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/ShawnPatrick-Barhorst/Word2Vec_Recommendation/refs/heads/main/goodreads_books.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jtBuBl_Day_B"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[['title', 'link', 'author', 'description']]\n",
        "dataset = dataset[dataset['description'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "N6AaWK5Ha5jo",
        "outputId": "3772d19c-3ba8-4cdf-d93c-a6ad4cc401b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "0                                           Inner Circle   \n",
              "1                                      A Time to Embrace   \n",
              "2                                               Take Two   \n",
              "4      The Millionaire Next Door: The Surprising Secr...   \n",
              "5                                            Black Sheep   \n",
              "...                                                  ...   \n",
              "52194                             The Stranger I Married   \n",
              "52195     The Opposite of Loneliness: Essays and Stories   \n",
              "52196                                  Sadako will leben   \n",
              "52197                                        Confessions   \n",
              "52198                      Going Rogue: An American Life   \n",
              "\n",
              "                                                    link  \\\n",
              "0      https://www.goodreads.com//book/show/630104.In...   \n",
              "1      https://www.goodreads.com//book/show/9487.A_Ti...   \n",
              "2      https://www.goodreads.com//book/show/6050894-t...   \n",
              "4      https://www.goodreads.com//book/show/998.The_M...   \n",
              "5      https://www.goodreads.com//book/show/311164.Bl...   \n",
              "...                                                  ...   \n",
              "52194  https://www.goodreads.com//book/show/15743072-...   \n",
              "52195  https://www.goodreads.com//book/show/18143905-...   \n",
              "52196  https://www.goodreads.com//book/show/1466878.S...   \n",
              "52197  https://www.goodreads.com//book/show/630103.Co...   \n",
              "52198  https://www.goodreads.com//book/show/6922622-g...   \n",
              "\n",
              "                                          author  \\\n",
              "0                      Kate Brian, Julian Peploe   \n",
              "1                                Karen Kingsbury   \n",
              "2                                Karen Kingsbury   \n",
              "4            Thomas J. Stanley, William D. Danko   \n",
              "5                                Georgette Heyer   \n",
              "...                                          ...   \n",
              "52194                                 Sylvia Day   \n",
              "52195                              Marina Keegan   \n",
              "52196                              Karl Bruckner   \n",
              "52197                                 Kate Brian   \n",
              "52198  Sarah Palin, Lynn Vincent, Dewey Whetsell   \n",
              "\n",
              "                                             description  \n",
              "0      Reed Brennan arrived at Easton Academy expecti...  \n",
              "1      Ideje az Ã¶lelÃ©snek TÃ¶rtÃ©net a remÃ©nyrÅl,...  \n",
              "2      Filmmakers Chase Ryan and Keith Ellison have c...  \n",
              "4      The incredible national bestseller that is cha...  \n",
              "5      With her high-spirited intelligence and good l...  \n",
              "...                                                  ...  \n",
              "52194  The unabridged, downloadable audiobook edition...  \n",
              "52195  An affecting and hope-filled posthumous collec...  \n",
              "52196  6. August 1945, 8 Uhr 15 Minuten - die kleine ...  \n",
              "52197  Sometimes the truth hurts....     Reed Brennan...  \n",
              "52198  is the #1  bestselling memoir from Sarah Palin...  \n",
              "\n",
              "[49624 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a228d59c-5c1d-45e9-872a-1d4072a16dba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>link</th>\n",
              "      <th>author</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Inner Circle</td>\n",
              "      <td>https://www.goodreads.com//book/show/630104.In...</td>\n",
              "      <td>Kate Brian, Julian Peploe</td>\n",
              "      <td>Reed Brennan arrived at Easton Academy expecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A Time to Embrace</td>\n",
              "      <td>https://www.goodreads.com//book/show/9487.A_Ti...</td>\n",
              "      <td>Karen Kingsbury</td>\n",
              "      <td>Ideje az Ã¶lelÃ©snek TÃ¶rtÃ©net a remÃ©nyrÅl,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Take Two</td>\n",
              "      <td>https://www.goodreads.com//book/show/6050894-t...</td>\n",
              "      <td>Karen Kingsbury</td>\n",
              "      <td>Filmmakers Chase Ryan and Keith Ellison have c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Millionaire Next Door: The Surprising Secr...</td>\n",
              "      <td>https://www.goodreads.com//book/show/998.The_M...</td>\n",
              "      <td>Thomas J. Stanley, William D. Danko</td>\n",
              "      <td>The incredible national bestseller that is cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Black Sheep</td>\n",
              "      <td>https://www.goodreads.com//book/show/311164.Bl...</td>\n",
              "      <td>Georgette Heyer</td>\n",
              "      <td>With her high-spirited intelligence and good l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52194</th>\n",
              "      <td>The Stranger I Married</td>\n",
              "      <td>https://www.goodreads.com//book/show/15743072-...</td>\n",
              "      <td>Sylvia Day</td>\n",
              "      <td>The unabridged, downloadable audiobook edition...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52195</th>\n",
              "      <td>The Opposite of Loneliness: Essays and Stories</td>\n",
              "      <td>https://www.goodreads.com//book/show/18143905-...</td>\n",
              "      <td>Marina Keegan</td>\n",
              "      <td>An affecting and hope-filled posthumous collec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52196</th>\n",
              "      <td>Sadako will leben</td>\n",
              "      <td>https://www.goodreads.com//book/show/1466878.S...</td>\n",
              "      <td>Karl Bruckner</td>\n",
              "      <td>6. August 1945, 8 Uhr 15 Minuten - die kleine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52197</th>\n",
              "      <td>Confessions</td>\n",
              "      <td>https://www.goodreads.com//book/show/630103.Co...</td>\n",
              "      <td>Kate Brian</td>\n",
              "      <td>Sometimes the truth hurts....     Reed Brennan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52198</th>\n",
              "      <td>Going Rogue: An American Life</td>\n",
              "      <td>https://www.goodreads.com//book/show/6922622-g...</td>\n",
              "      <td>Sarah Palin, Lynn Vincent, Dewey Whetsell</td>\n",
              "      <td>is the #1  bestselling memoir from Sarah Palin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49624 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a228d59c-5c1d-45e9-872a-1d4072a16dba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a228d59c-5c1d-45e9-872a-1d4072a16dba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a228d59c-5c1d-45e9-872a-1d4072a16dba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfb47bdb-3848-4d07-8bfe-099fc4880acc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfb47bdb-3848-4d07-8bfe-099fc4880acc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfb47bdb-3848-4d07-8bfe-099fc4880acc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cfb82d73-13a4-43a9-8df6-d8698c0049f8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cfb82d73-13a4-43a9-8df6-d8698c0049f8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 49624,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47237,\n        \"samples\": [\n          \"The Great Cheese Conspiracy\",\n          \"Batman, Volume 2: The City of Owls\",\n          \"Five Dares\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49624,\n        \"samples\": [\n          \"https://www.goodreads.com//book/show/31823637-the-desert-princess\",\n          \"https://www.goodreads.com//book/show/2010730.Outside_The_Dog_Museum\",\n          \"https://www.goodreads.com//book/show/59146.Marie_Antoinette\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26516,\n        \"samples\": [\n          \"Ella Frank, Chelsea Hatfield, J.F. Harding\",\n          \"Louise Gornall\",\n          \"Dale A. Fife\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49252,\n        \"samples\": [\n          \" When the   calls someone \\\"the greatest crime writer of our time, perhaps ever,\\\" that's no small compliment. This talented author has shown an extraordinary range in his work, from westerns to crime stories (both contemporary and historical) to a novel about baseball and more. In   Elmore \\\"Dutch\\\" Leonard breaks new ground  When the   calls someone \\\"the greatest crime writer of our time, perhaps ever,\\\" that's no small compliment. This talented author has shown an extraordinary range in his work, from westerns to crime stories (both contemporary and historical) to a novel about baseball and more. In   Elmore \\\"Dutch\\\" Leonard breaks new ground with a fast-paced, multifaceted tale of Prohibition-era crime, told from multiple perspectives that reflect the unexpected shifts of allegiance in this turbulent time. Set against a backdrop of speakeasys and shootouts, fast cars and even faster women, this stirring tale recounts a time when life was cheap on both sides of the law. The story unfolds in Oklahoma, featuring the exploits of four \\\"hot kids\\\" -- young lawman Carl Webster, bad-seed oilman's son Jack Belmont, glamorous gun moll Louly Brown, and true-crime journalist Tony Antonelli.  Carl Webster, since his first personal encounter with crime as a teenage witness to a brutal robbery by notorious crook Emmet Long, has sought justice. His keen mind and sharpshooter's eye quickly build him a hot reputation in the U.S. Marshals Service, especially after he declares, \\\"If I have to pull my weapon, I'll shoot to kill\\\" and proves he has what it takes to back up his claim... Jack Belmont has big dreams. His goal is to join the ranks of America's most feared criminals to replace John Dillinger as Public Enemy No. 1. This young outlaw has all the instincts of a cold-blooded killer, plus a powerful thirst for glory. He's got a long way to go to join the ranks of Baby Face Nelson, Pretty Boy Floyd, Clyde Barrow and Bonnie Parker, and Machine-Gun Kelly but he's off to a good enough start that Webster is hot on his trail... Louly Brown started with nothing but she wasn't about to settle for that. Her first claim to fame came when her cousin married Charley \\\"Pretty Boy\\\" Floyd. Later, running off with ex-con Joe Young added spice to her life. But she was smart enough to see that helping Carl Webster put a stop to Joe's crime spree would be a better deal than sharing his fate. After the smoke cleared, Louly really came into her own, selling her story to the papers, then setting her sights on the handsome lawman who'd captured her heart. Tony Antonelli loves the danger and fame that come along with rubbing shoulders with heartless gangsters, dedicated lawmen, gorgeous gun molls, and bloodthirsty vigilantes in the course of his work for   magazine. Whether he's writing about bank robbers or the Black Hand, the KKK or rum running, or hot young lawmen and cold-blooded killers and their sexy sidekicks, Tony views other people's troubles as more than just bread-and-butter; they provide an adrenaline-charged kick to his own life, as well as vicarious thrills for eager readers. Elmore Leonard hits his target with   an unforgettable tale of high adventure where the crooks are out to prove that crime really can pay and where federal marshals trade high risks for low salary to bring these wanted felons in \\\"dead or alive.\\\"\",\n          \"At Animal Ark, Mandy Hope helps her parents treat animals of all shpaes and sizes. Even outside the clinic, Mandy can't resist helping any animal in need. Wayne Skilton has just moved to Mandy's town from London. At first, he's not enthusiastic about country life and he's not very friendly. But a nicer side of Wayne is revealed when he's seen petting a tabby cat from the n At Animal Ark, Mandy Hope helps her parents treat animals of all shpaes and sizes. Even outside the clinic, Mandy can't resist helping any animal in need. Wayne Skilton has just moved to Mandy's town from London. At first, he's not enthusiastic about country life and he's not very friendly. But a nicer side of Wayne is revealed when he's seen petting a tabby cat from the neighborhood. When Many and James see the cat again and realize it has an eye infection, they must seek medical help and notify the cat's owner - an old lady named Mrs. Webb, who's a recluse and won't answer her door. But Wayne's soft side soon comes in handy when he finds a way to make contact with her. Who is this mysterious woman, and what can the kids do to help her and her beautiful cat?\",\n          \"Valencia is the fast-paced account of one girl's search for love and high times in the drama-filled dyke world of San Francisco's Mission District. Through a string of narrative moments, Tea records a year lived in a world of girls: there's knife-wielding Marta, who introduces Michelle to a new world of radical sex; Willa, Michelle's tormented poet-girlfriend; Iris, the be Valencia is the fast-paced account of one girl's search for love and high times in the drama-filled dyke world of San Francisco's Mission District. Through a string of narrative moments, Tea records a year lived in a world of girls: there's knife-wielding Marta, who introduces Michelle to a new world of radical sex; Willa, Michelle's tormented poet-girlfriend; Iris, the beautiful boy-dyke who ran away from the South in a dust cloud of drama; and Iris's ex, Magdalena Squalor, to whom Michelle turns when Iris breaks her heart. Valencia conveys a blend of youthful urgency and apocalyptic apathy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Imn35riNA76i",
        "outputId": "cbd32a22-45e5-4845-b9aa-4c92103b9589"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The \"New York Times\" Number One bestseller from 1976 is back in this great new package. As the day begins at First Mercantile American Bank, so do the high-stake risks, the public scandals, and the private affairs. It is the inside world where secret million-dollar deals are made, manipulated, and sweetened with sex by the men and women who play to win.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset['description'][42]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Cleaning and the NLTK Library"
      ],
      "metadata": {
        "id": "8Kazm2WDsgng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLTK library consists of a variety of natural language tools that will help us clean our text. The goal of the cleaning is to get rid of non-text and to get similar words to match each other. For example run and running are similar so we should in this instance, remove the ning from running to make them the same. This will shrink the library of our model."
      ],
      "metadata": {
        "id": "wUarmKzZsjND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of this functionality will help us remove stopwords such as [a, is, but, and] and so on, these are words that carry little meaning and serve as intermediary words to help our speech. The model will not gain from this so they are removed."
      ],
      "metadata": {
        "id": "qRyGyK4UtR4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another function is the stemmer, which will help us snip off various suffixes to make similar words match."
      ],
      "metadata": {
        "id": "BEpYQIvStfgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnnAkzxSBHrp",
        "outputId": "0d741340-bf47-4d55-f7f5-9265944e3061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I use a function to make everything lowercase and to remove all non letters as well as \"'s\", to insure it doesn't get recognized as a word later"
      ],
      "metadata": {
        "id": "kkKFVSk4s_y9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "suv92qXkzZpZ"
      },
      "outputs": [],
      "source": [
        "def clean(row):\n",
        "  sub = re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower()\n",
        "  cleaned = cleaned_sentence = re.sub(r\"'s\\b\", \"\", sub)\n",
        "  return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LdlQ39n3zyHO"
      },
      "outputs": [],
      "source": [
        "brief_cleaning = [clean(row) for row in dataset['description']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section of code I create a new list for my cleaned descriptions. I first tokenize the sequences, remove stopwords, and stem all words. Once I do this the data is clean."
      ],
      "metadata": {
        "id": "jGNkAeadtNCn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8MnOWKY7U92"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n",
        "cleaned_descriptions = []\n",
        "\n",
        "\n",
        "cleaned = [clean(row) for row in dataset['description']]\n",
        "for description in cleaned:\n",
        "  tokens = word_tokenize(description)\n",
        "  cleaned_tokens = []\n",
        "  for token in tokens:\n",
        "    if token not in stop_words:\n",
        "      stemmed = stemmer.stem(token)\n",
        "      cleaned_tokens.append(stemmed)\n",
        "  cleaned_descriptions.append(cleaned_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['description'][0]"
      ],
      "metadata": {
        "id": "FizTl3Tk3qpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8poDropalXG"
      },
      "outputs": [],
      "source": [
        "cleaned_descriptions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYYG_fhpkgsK"
      },
      "source": [
        "##Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the gensim library we can import a Word2Vec model already trained on a large corpus by google. This corpus consists of webpages like Wikipedia, various dictionaries, etc."
      ],
      "metadata": {
        "id": "wVge_ByBuBT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will still have to do a little bit of training so the model understands some of the words in our particular dataset. This is done below."
      ],
      "metadata": {
        "id": "vahIRB_4uWFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOdD8zpqhefB"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbuOMvarkese"
      },
      "outputs": [],
      "source": [
        "cores = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgbL3Fl9klJn"
      },
      "outputs": [],
      "source": [
        "w2v_model = Word2Vec(min_count=20,      # Removes low frequency words with less than \"min_count\" occurances\n",
        "                     window=2,          # Window size both left and right\n",
        "                     sample=6e-5,       # Removes high frequency words, words appearing more than sample% of word occurances are down sampled\n",
        "                     alpha=0.03,        # Learning Rate\n",
        "                     min_alpha=0.0007,  # Minimum Learning Rate\n",
        "                     negative=20,       # Negative sampling technique, improves performance by introducing random words into the window to reinforce the fact these words don't appear together\n",
        "                     workers=cores-1)\n",
        "\n",
        "w2v_model.build_vocab(cleaned_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wppuy906k9MS"
      },
      "outputs": [],
      "source": [
        "t = time()\n",
        "w2v_model.train(cleaned_descriptions, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFDhbrNLlqVU"
      },
      "outputs": [],
      "source": [
        "#w2v_model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Recommender"
      ],
      "metadata": {
        "id": "G4C4_MIwu_Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model is finally setup we can use create a vector representation. To do this we use the word2vec model to find a vector of each word and then average the vectors of each word. This is done below."
      ],
      "metadata": {
        "id": "BVpA0kg7ukQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_vectors = []\n",
        "for description in cleaned_descriptions:\n",
        "  word_vectors = [w2v_model.wv[word] for word in description if word in w2v_model.wv]\n",
        "  sentence_vector = np.mean(word_vectors, axis=0)\n",
        "  sentence_vectors.append(sentence_vector)"
      ],
      "metadata": {
        "id": "f72Qy2PmDfML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_vectors)"
      ],
      "metadata": {
        "id": "i3pe_asQFzsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases the description was an empty string but didn't show an Nan value. So the model returned Nan values for them and we will have to remove those rows again."
      ],
      "metadata": {
        "id": "pjcJP6YsvGSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['vector'] = sentence_vectors\n",
        "dataset = dataset[dataset['vector'].notna()]"
      ],
      "metadata": {
        "id": "JFICv1iwH6u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have a new dataset with a vector representation of each description. This is great!"
      ],
      "metadata": {
        "id": "sSt_jUG7vTK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "jOof-Az3Lt4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cosine Similarity"
      ],
      "metadata": {
        "id": "5Iy5Gp_OvcfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity is a method of finding similarity between 2 objects by finding the cosine, between the angle of the two objects."
      ],
      "metadata": {
        "id": "MKRHdgVQwKG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason why we would want to use this as opposed to euclidean similarity is due to the fact that cosine doesn't rely on distances and is therfore immune to the high dimensionality that is present. Essentially cosine normalizes the distance."
      ],
      "metadata": {
        "id": "79KyG8Y1wUqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*FTVRr_Wqz-3_k6Mk6G4kew.png\">"
      ],
      "metadata": {
        "id": "A0tnQos7vqrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I create a quick example using the first book and finding the similarity of that book between all other books. I then create a new column and a new dataset that I will then sort to find the highest similarities."
      ],
      "metadata": {
        "id": "_IMUbmmhwouD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "vector1 = np.array(dataset['vector'][0])\n",
        "vector1 = vector1.reshape(1,-1)\n",
        "similarities = []\n",
        "\n",
        "for vector2 in dataset['vector']:\n",
        "  vector2 = np.array(vector2)\n",
        "  vector2 = vector2.reshape(1, -1)\n",
        "\n",
        "  similarities.append(cosine_similarity(vector1, vector2))"
      ],
      "metadata": {
        "id": "JBU-1XzTMGke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_df = dataset\n",
        "similarity_df['similarity'] = similarities"
      ],
      "metadata": {
        "id": "DSkerf7SQqV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what we will be creating in a function shortly. However for viewing purposes you can see the similarity score between the first book \"Inner Circle\" and various other books."
      ],
      "metadata": {
        "id": "qM77YFzTw4LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_df"
      ],
      "metadata": {
        "id": "Pw76Z2drWEPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_df = similarity_df.sort_values(by='similarity', ascending=False)"
      ],
      "metadata": {
        "id": "zG3gG_0eiEEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By sorting them we can get the most similar books in our list and recommend them to a person."
      ],
      "metadata": {
        "id": "VO8syMVaxGWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_df"
      ],
      "metadata": {
        "id": "wS90HBXGxEbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I put it all into a single function and used a book from above as a quick example. You can see that it returns us the top 5 most similar books."
      ],
      "metadata": {
        "id": "jRXKcajixDtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(title, n=5):\n",
        "\n",
        "  #Check if book exists\n",
        "  if title not in dataset['title'].values:\n",
        "    print(\"Book not found\")\n",
        "    return\n",
        "\n",
        "  indices_with_string = dataset[dataset['title'].str.contains(title)].index\n",
        "\n",
        "  #get embedding and reshape\n",
        "  vector1 = np.array(dataset['vector'][indices_with_string[0]])\n",
        "  vector1 = vector1.reshape(1,-1)\n",
        "  similarities = []\n",
        "\n",
        "  #assemble every other embedding\n",
        "  for vector2 in dataset['vector']:\n",
        "    vector2 = np.array(vector2)\n",
        "    vector2 = vector2.reshape(1, -1)\n",
        "\n",
        "    #Get similarity\n",
        "    similarities.append(cosine_similarity(vector1, vector2))\n",
        "\n",
        "  #Create copy of original dataframe then add distance metrics\n",
        "  similarity_df = dataset.copy()\n",
        "  similarity_df['similarity'] = similarities\n",
        "\n",
        "  #Sort values\n",
        "  sorted_df = similarity_df.sort_values(by='similarity', ascending=False)\n",
        "  sorted_df = sorted_df[sorted_df['title'] != title]\n",
        "\n",
        "  #Print top N books\n",
        "  for idx, title in enumerate(sorted_df['title'][:n], start=1):\n",
        "    print(f\"{idx}: {title}\")"
      ],
      "metadata": {
        "id": "wkEl_xTcCXy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('The Old Man and the Sea')"
      ],
      "metadata": {
        "id": "Szqm-g5akLRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('The Martian')"
      ],
      "metadata": {
        "id": "NWsfvVxk63BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Darkly Dreaming Dexter')"
      ],
      "metadata": {
        "id": "vU0IzVRlAilf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('A Clockwork Orange')"
      ],
      "metadata": {
        "id": "oTjgsXEZCO4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('V for Vendetta')"
      ],
      "metadata": {
        "id": "3bCQs3pnGpFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}